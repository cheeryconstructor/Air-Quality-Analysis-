# -*- coding: utf-8 -*-
"""CLC_ICTC

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PGTeyY7nb1bQ0XO0ehYrh4RXKzX3mSEH
"""

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

labels = {'Very low':0, 'Low':1, 'Moderate':2, 'High':3, 'Very High':4}

mat = np.loadtxt('CLC_train.csv',delimiter=',',skiprows=1,usecols=(2,3,4,5,6,7,8,9,10,11,12,13,14))
classes = np.loadtxt('CLC_train.csv',dtype=str,delimiter=',',skiprows=1,usecols=(15))

classes = np.array([labels[z] for z in classes])

mat[mat==-200] = np.nan

means = np.nanmean(mat,axis=0)
stddevs = np.nanstd(mat,axis=0)

mat[np.isnan(mat)] = -200
#
naninds = np.where(np.isnan(mat))
#
mat[naninds] = np.take(means, naninds[1])

x_norm = (mat-means)/stddevs

y = tf.keras.utils.to_categorical(classes)

#
model = tf.keras.Sequential([
                tf.keras.layers.Dense(10,input_shape=(13,),activation='relu'),
                tf.keras.layers.Dense(7,activation='relu'),
                tf.keras.layers.Dense(5,activation='softmax')
            ])
#
#model = tf.keras.models.load_model('my_model3')
#
print(model.summary())
##
model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])
model.fit(x_norm,y,epochs=500,batch_size=1024)
#
model.save('my_model')

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, classification_report, cohen_kappa_score, confusion_matrix, f1_score, log_loss

tf.random.set_seed(786)
np.random.seed(786)

labels = {'Very low':0, 'Low':1, 'Moderate':2, 'High':3, 'Very High':4}

mat = np.loadtxt('CLC_train.csv',delimiter=',',skiprows=1,usecols=(2,3,4,5,6,7,8,9,10,11,12,13,14))
classes = np.loadtxt('CLC_train.csv',dtype=str,delimiter=',',skiprows=1,usecols=(15))

classes = np.array([labels[z] for z in classes])

mat[mat==-200] = np.nan

means = np.nanmean(mat,axis=0)
stddevs = np.nanstd(mat,axis=0)

mat[np.isnan(mat)] = -200

#naninds = np.where(np.isnan(mat))

#mat[naninds] = np.take(means, naninds[1])

x_norm = (mat-means)/stddevs

y = tf.keras.utils.to_categorical(classes)

#model = tf.keras.Sequential([
#                tf.keras.layers.Dense(10,input_shape=(13,),activation='relu'),
#                tf.keras.layers.Dense(7,activation='relu'),
#                tf.keras.layers.Dense(5,activation='softmax')
#            ])

model = tf.keras.models.load_model('my_model')

print(model.summary())

model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])
#model.fit(x_norm,y,epochs=500,batch_size=1024)

#model.save('my_model3')

ypred_prob = model.predict(x_norm)
ypred = np.argmax(ypred_prob,axis=1)

print()
print("Accuracy:", accuracy_score(classes,ypred))
print("F1 score:", f1_score(classes,ypred,average='weighted',zero_division=0))
print("Cohen Kappa Score:",cohen_kappa_score(classes,ypred))
print("Confusion Matrix:")
print(confusion_matrix(classes,ypred))
print("Classification Report:")
print(classification_report(classes,ypred,zero_division=0))

# feature importance
features = np.loadtxt('CLC_test.csv',delimiter=',',usecols=(2,3,4,5,6,7,8,9,10,11,12,13,14),dtype=str,max_rows=1)
num_features = features.shape[0]

# original loss
orig_loss = log_loss(classes,ypred_prob)
print("Original Loss:",orig_loss)
print()

feature_importance = np.zeros((num_features))

for i in range(num_features):
    copy = np.copy(x_norm)

    np.random.shuffle(copy[:,i])
    yf = model.predict(copy)
    shuffled_loss = log_loss(classes,yf)

    feature_importance[i] = abs(shuffled_loss-orig_loss)

print("Feature Importance:")
zipped_fi = sorted(zip(feature_importance,features), reverse=True)

for i in range(num_features):
    print(zipped_fi[i][1]+':', zipped_fi[i][0])

features = [j for i,j in zipped_fi]
feature_importance = [i for i,j in zipped_fi]

plt.bar(features,feature_importance)
plt.show()

